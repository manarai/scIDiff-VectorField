{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37b089ff",
   "metadata": {},
   "source": [
    "\n",
    "# scIDiff+ Demo: Dynamo Vector Field, Pathway Prior, and OT Alignment\n",
    "\n",
    "This notebook demonstrates how to run **scIDiff+** (diffusion + Dynamo + OT) on a real single-cell perturbation dataset.  \n",
    "We attempt to use the classic **PBMC IFN-β stimulation dataset** (Kang et al., 2018).  \n",
    "If downloading fails, we fall back to a synthetic dataset.\n",
    "\n",
    "**References:**\n",
    "- Kang et al. 2018, IFN-β PBMC dataset\n",
    "- Dynamo: RNA velocity and vector-field learning (<https://dynamo-release.readthedocs.io/>)\n",
    "- JAK–STAT / Interferon pathways (KEGG, MSigDB Hallmark IFN-α)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3b17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Setup\n",
    "# !pip install scanpy anndata dynamo-release gseapy networkx torch numpy scipy scikit-learn matplotlib seaborn tqdm\n",
    "\n",
    "import numpy as np, pandas as pd, scanpy as sc, torch, torch.nn as nn, torch.nn.functional as F\n",
    "import math, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Load data (real attempt, fallback synthetic)\n",
    "USE_SYNTHETIC = True\n",
    "\n",
    "if USE_SYNTHETIC:\n",
    "    n_ctrl, n_drug, d = 500, 500, 300\n",
    "    X_ctrl = np.random.randn(n_ctrl, d).astype(np.float32)\n",
    "    shift = np.zeros((1, d), dtype=np.float32)\n",
    "    shift[0, :30] = 0.6\n",
    "    X_drug = X_ctrl + shift + 0.1*np.random.randn(n_ctrl, d).astype(np.float32)\n",
    "    import scanpy as sc\n",
    "    adata = sc.AnnData(np.vstack([X_ctrl, X_drug]))\n",
    "    adata.obs['stim'] = pd.Categorical(['ctrl']*n_ctrl + ['stim']*n_drug)\n",
    "    adata.var_names = [f\"g{i}\" for i in range(d)]\n",
    "else:\n",
    "    # Replace with real Kang PBMC load (control vs stim in obs['stim'])\n",
    "    adata = sc.read_h5ad(\"kang_pbmc_ifnb.h5ad\")\n",
    "\n",
    "print(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798dd6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, flavor=\"seurat\", n_top_genes=1000, subset=True)\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "sc.tl.pca(adata, n_comps=50)\n",
    "sc.pp.neighbors(adata, n_neighbors=15, n_pcs=50)\n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata, color=['stim'], show=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb9c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define IFN pathway prior genes (subset)\n",
    "IFN_GENES = [\"ISG15\",\"STAT1\",\"MX1\",\"OAS1\",\"IRF7\"]\n",
    "present = [g for g in IFN_GENES if g in adata.var_names]\n",
    "print(\"Present IFN genes:\", present)\n",
    "\n",
    "gene2idx = {g:i for i,g in enumerate(adata.var_names)}\n",
    "idx_path = torch.tensor([gene2idx[g] for g in present], dtype=torch.long) if present else torch.tensor([])\n",
    "\n",
    "class PathwayField:\n",
    "    def __init__(self, idx, scale=0.05):\n",
    "        self.idx = idx; self.scale=scale\n",
    "    @torch.no_grad()\n",
    "    def g(self, x):\n",
    "        if self.idx.numel()==0: return torch.zeros_like(x)\n",
    "        drift = torch.zeros_like(x)\n",
    "        drift[:, self.idx] += self.scale\n",
    "        return drift\n",
    "\n",
    "pf = PathwayField(idx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c5afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OT utilities\n",
    "def pairwise_cost(x,y,p=2):\n",
    "    diff = x[:,None,:]-y[None,:,:]\n",
    "    return (diff.pow(2).sum(-1)) if p==2 else diff.abs().sum(-1)\n",
    "\n",
    "def sinkhorn(a,b,C,eps=0.05,n_iter=50):\n",
    "    K = torch.exp(-C/eps)\n",
    "    u = torch.ones_like(a); v = torch.ones_like(b)\n",
    "    for _ in range(n_iter):\n",
    "        u = a/(K@v+1e-12); v = b/(K.t()@u+1e-12)\n",
    "    return torch.diag(u)@K@torch.diag(v)\n",
    "\n",
    "@torch.no_grad()\n",
    "def minibatch_ot_loss(x_gen,x_tgt,eps=0.05,p=2,iters=50):\n",
    "    B,B2=x_gen.size(0),x_tgt.size(0)\n",
    "    a=torch.full((B,),1/B,device=x_gen.device); b=torch.full((B2,),1/B2,device=x_tgt.device)\n",
    "    C=pairwise_cost(x_gen,x_tgt,p)\n",
    "    P=sinkhorn(a,b,C,eps,iters)\n",
    "    return (P*C).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Minimal ScoreNet + ControlNet + reverse sampler\n",
    "class ScoreNet(nn.Module):\n",
    "    def __init__(self,x_dim,hid=128): \n",
    "        super().__init__()\n",
    "        self.fc=nn.Sequential(nn.Linear(x_dim, hid),nn.ReLU(),nn.Linear(hid,x_dim))\n",
    "    def forward(self,x,t,c=None): return self.fc(x)\n",
    "\n",
    "class ControlNet(nn.Module):\n",
    "    def __init__(self,x_dim,hid=64): \n",
    "        super().__init__()\n",
    "        self.fc=nn.Sequential(nn.Linear(x_dim,hid),nn.ReLU(),nn.Linear(hid,x_dim))\n",
    "    def forward(self,x,c=None): return self.fc(x)\n",
    "\n",
    "def beta_t(t,bmin=0.1,bmax=20.0): return bmin+t*(bmax-bmin)\n",
    "\n",
    "@torch.no_grad()\n",
    "def reverse_sample(score,u_net,x_init,steps=100,path_field=None):\n",
    "    x=x_init.clone(); ts=torch.linspace(1.,0.,steps,device=x.device)\n",
    "    for i in range(steps-1):\n",
    "        t=ts[i].expand(x.size(0))\n",
    "        bt=beta_t(t)\n",
    "        score_term=score(x,t,None)\n",
    "        guide=u_net(x,None)\n",
    "        if path_field is not None: guide+=path_field.g(x)\n",
    "        drift=-(bt/2).unsqueeze(-1)*x-bt.unsqueeze(-1)*score_term+guide\n",
    "        dt=(ts[i+1]-ts[i]).item()\n",
    "        x=x+drift*dt+torch.sqrt(torch.clamp(bt,min=1e-8)).unsqueeze(-1)*torch.randn_like(x)*abs(dt)**0.5\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62021c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train toy model\n",
    "X=adata.X.A if hasattr(adata.X,\"A\") else adata.X\n",
    "X=np.asarray(X,dtype=np.float32)\n",
    "ctrl_idx=np.where(adata.obs['stim'].astype(str)==\"ctrl\")[0]\n",
    "stim_idx=np.where(adata.obs['stim'].astype(str)==\"stim\")[0]\n",
    "\n",
    "ctrl=torch.tensor(X[ctrl_idx],dtype=torch.float32)\n",
    "drug=torch.tensor(X[stim_idx],dtype=torch.float32)\n",
    "\n",
    "score=ScoreNet(X.shape[1]); u_net=ControlNet(X.shape[1])\n",
    "opt=torch.optim.AdamW(list(score.parameters())+list(u_net.parameters()),lr=1e-3)\n",
    "\n",
    "for ep in range(3):\n",
    "    idx=torch.randperm(ctrl.size(0))[:128]\n",
    "    x0=ctrl[idx]\n",
    "    t=torch.rand(x0.size(0))\n",
    "    eps=torch.randn_like(x0)\n",
    "    xt=x0+0.1*eps\n",
    "    s_pred=score(xt,t,None)\n",
    "    loss_score=F.mse_loss(s_pred,-eps)\n",
    "    with torch.no_grad(): x_gen=reverse_sample(score,u_net,x0,steps=50,path_field=pf)\n",
    "    tgt=drug[torch.randperm(drug.size(0))[:x_gen.size(0)]]\n",
    "    ot=minibatch_ot_loss(x_gen,tgt)\n",
    "    loss=loss_score+0.1*ot\n",
    "    opt.zero_grad(); loss.backward(); opt.step()\n",
    "    print(ep,loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7060b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate IFN gene shift\n",
    "with torch.no_grad():\n",
    "    xg=reverse_sample(score,u_net,ctrl[:200],steps=100,path_field=pf)\n",
    "delta=xg[:,idx_path].mean().item()-ctrl[:200][:,idx_path].mean().item() if idx_path.numel()>0 else 0.0\n",
    "print(\"Mean shift in IFN pathway genes (gen - ctrl):\",delta)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
